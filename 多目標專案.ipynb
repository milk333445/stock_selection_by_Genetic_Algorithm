{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KYN405fonz-q"
      },
      "outputs": [],
      "source": [
        "#抓美股資料\n",
        "import pandas_datareader.data as pdr\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "yf.pdr_override()\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp500= [\n",
        "    'AAPL', 'MSFT', 'AMZN', 'GOOGL', 'GOOG',\n",
        "    'NVDA', 'JPM', 'JNJ', 'V', 'PG',\n",
        "    'DIS', 'PYPL', 'BAC', 'TSM', 'WMT',\n",
        "    'HD', 'UNH', 'MA', 'ADBE', 'CMCSA',\n",
        "    'XOM', 'VZ', 'CRM', 'PEP', 'NFLX',\n",
        "    'CSCO', 'MRK', 'PFE', 'ABT', 'ABBV',\n",
        "    'T', 'COST', 'CVX', 'INTC', 'ACN',\n",
        "    'AMD', 'TMUS', 'QCOM', 'ORCL', 'NKE',\n",
        "    'KO', 'NEE', 'MDT', 'AVGO', 'MCD',\n",
        "    'C', 'LLY', 'AMGN', 'DHR', 'HON',\n",
        "    'TXN', 'UNP', 'LMT', 'MO', 'BMY',\n",
        "    'NVS', 'PM', 'GILD', 'IBM', 'LIN',\n",
        "    'CHTR', 'NOW', 'AMT', 'TMO', 'MMM',\n",
        "    'BA', 'BLK', 'UPS', 'DE', 'FIS',\n",
        "    'SBUX', 'AXP', 'GS', 'CAT', 'ISRG',\n",
        "    'CVS', 'CI', 'SPGI', 'PLD', 'ADP',\n",
        "    'CME', 'SO', 'TGT', 'ANTM', 'TJX',\n",
        "    'VRTX', 'CCI', 'SCHW', 'PNC', 'BDX',\n",
        "    'VRTX', 'CCI', 'SCHW', 'PNC', 'BDX',\n",
        "    'SYK', 'D', 'APD', 'EW', 'LOW',\n",
        "    'TFC', 'TJX', 'ATVI', 'MU', 'AMAT',\n",
        "    'COP', 'GM', 'FDX', 'SPG', 'AMD',\n",
        "    'CI', 'EBAY', 'VLO', 'PXD', 'DUK',\n",
        "    'DD', 'WFC', 'MPC', 'BAX', 'LUV',\n",
        "    'CTSH', 'APTV', 'ADM', 'AON', 'AEP',\n",
        "    'CB', 'ETN', 'NSC', 'REGN', 'SYY',\n",
        "    'IQV', 'ROST', 'TRV', 'EXC', 'WM',\n",
        "    'FOX', 'LRCX', 'BKNG', 'BLL', 'IFF',\n",
        "    'ECL', 'CTVA', 'SWKS', 'BSX', 'BXP',\n",
        "    'AFL', 'XLNX', 'MNST', 'FISV', 'CFG',\n",
        "    'PGR', 'PH', 'MCK', 'ANSS', 'FRC',\n",
        "    'WBA', 'ADI', 'KEY', 'GLW', 'EMR',\n",
        "    'ALL', 'ZTS', 'TWTR', 'MMC', 'PSA',\n",
        "    'HIG', 'CPRT', 'IDXX', 'AMP', 'HCA',\n",
        "    'VFC', 'LYB', 'WELL', 'A', 'APH',\n",
        "    'HLT', 'DFS', 'PXD', 'CNC', 'DLR',\n",
        "    'STZ', 'ALB', 'NTAP', 'BKR', 'DXCM', 'INFO',\n",
        "    'MCO', 'DOW', 'SWK', 'OXY', 'AIG',\n",
        "    'PFG', 'WY', 'CTAS', 'GL', 'ETSY',\n",
        "    'DRI', 'KMB', 'ANET', 'LH', 'RMD',\n",
        "    'HLT', 'BK', 'PEAK', 'MXIM', 'LEN',\n",
        "    'VTR', 'CERN', 'SNPS', 'HSY', 'EIX',\n",
        "    'STX', 'ALXN', 'PSX', 'HOLX', 'CDW',\n",
        "    'FAST', 'MSCI', 'DLTR', 'VRSN', 'ESS',\n",
        "    'ODFL', 'AJG', 'RCL', 'LYV', 'COF',\n",
        "    'CBRE', 'MLM', 'PKI', 'AME', 'FFIV',\n",
        "    'KEYS', 'HAS', 'MCHP', 'IR', 'DG',\n",
        "    'STE', 'ZBRA', 'DLB', 'FLT', 'SNOW',\n",
        "    'TTWO', 'PENN', 'HWM', 'GRMN', 'NDAQ',\n",
        "    'NVR', 'AN', 'MTD', 'LEN', 'CTXS',\n",
        "    'PANW', 'SYF', 'WST', 'PAYC', 'GRUB',\n",
        "    'IP', 'HII', 'ATO', 'VTRS', 'CPB',\n",
        "    'REG', 'QRVO', 'RJF', 'L', 'AOS',\n",
        "    'ETR', 'HPQ', 'PTON', 'WAB', 'LW',\n",
        "    'CMA', 'FANG', 'CMS', 'CHD', 'HES',\n",
        "    'TT', 'LDOS', 'VNO', 'CPRI', 'WAT',\n",
        "    'PNR', 'DOCU', 'DVA', 'NUE', 'KIM',\n",
        "    'HAS', 'VIAC', 'AAL', 'AMCR', 'ZION',\n",
        "    'IRM', 'ARE', 'MKTX', 'DVN', 'EXR',\n",
        "    'FOXA', 'UNM', 'UAL', 'HFC', 'WRK',\n",
        "    'ALK', 'MYL', 'KMX', 'MGM', 'BEN',\n",
        "    'FLIR', 'URI', 'LNT', 'HBAN', 'STT'\n",
        "]\n"
      ],
      "metadata": {
        "id": "nw1qTexIoCjx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp500_top_250 = sp500[:250]\n",
        "len(sp500_top_250)\n",
        "sp500_top_250"
      ],
      "metadata": {
        "id": "xtFpMsbboEfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#寫機器學習函數\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import copy"
      ],
      "metadata": {
        "id": "exSNpVzFo8SU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#打包成函數\n",
        "def get_stock_data(stock_code, start_date, end_date):\n",
        "    #取得股票資料\n",
        "    df = pdr.get_data_yahoo([stock_code], start_date, end_date)\n",
        "    df.columns = [col.lower() for col in df.columns]\n",
        "    ta_list = talib.get_functions()\n",
        "    for x in ta_list:\n",
        "        try:\n",
        "            # x 為技術指標的代碼，透過迴圈填入，再透過 eval 計算出 output\n",
        "            output = eval('abstract.'+x+'(df)')\n",
        "            # 如果輸出是一維資料，幫這個指標取名為 x 本身；多維資料則不需命名\n",
        "            output.name = x.lower() if type(output) == pd.core.series.Series else None\n",
        "            # 透過 merge 把輸出結果併入 df DataFrame\n",
        "            df = pd.merge(df, pd.DataFrame(output), left_on = df.index, right_on = output.index)\n",
        "            df = df.set_index('key_0')\n",
        "        except:\n",
        "            print(x)\n",
        "    # 將股票價格和報酬率向後滯後一期\n",
        "    df['return'] = df['adj close'].pct_change()\n",
        "    df['change'] = (df['adj close'] > df['open']).astype(int)\n",
        "    # 刪除包含缺失值的行\n",
        "    data = df\n",
        "    data = data.drop(['acos', 'asin'], axis=1)\n",
        "    data = data.dropna()\n",
        "    data = data.reset_index(drop=True)\n",
        "    data = data.astype('float')\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "FiJ_0cqgt1RJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_stock_price_ver1(data, keep_cols):\n",
        "    # 根据 keep_cols 的值删除需要删除的列\n",
        "    # 用除了漲跌的欄位作為自變數，去預測股價漲跌\n",
        "    df = copy.deepcopy(data)\n",
        "    df.fillna(0, inplace=True)\n",
        "    df['stddev_lagging'] = df['stddev'].shift(-1)\n",
        "    df = df.dropna()\n",
        "    scaler = StandardScaler()\n",
        "    X = df.drop(['stddev_lagging'], axis=1)\n",
        "    drop_cols = [col for i, col in enumerate(X.columns) if not keep_cols[i]]\n",
        "    X = X.drop(drop_cols, axis=1)\n",
        "    X = X.dropna()\n",
        "    X = scaler.fit_transform(X)\n",
        "    y = df['stddev_lagging'].values.reshape(-1,1)\n",
        "    y = scaler.fit_transform(y)\n",
        "    # 分割資料集為訓練集和測試集\n",
        "    X_train, y_train = X, y\n",
        "    # 創建隨機森林模型\n",
        "    rf = RandomForestRegressor(random_state=10, n_jobs=-1)\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_train)\n",
        "    # 計算測試集的 AUC 分數\n",
        "    mse_score = mean_squared_error(y_train, y_pred)\n",
        "    return mse_score"
      ],
      "metadata": {
        "id": "ziC281xvo-m8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_stock_price_ver2(data, keep_cols):\n",
        "    # 根据 keep_cols 的值删除需要删除的列\n",
        "    # 用除了漲跌的欄位作為自變數，去預測股價漲跌\n",
        "    df = copy.deepcopy(data)\n",
        "    df.fillna(0, inplace=True)\n",
        "    df['return_lagging'] = df['return'].shift(-1)\n",
        "    df = df.dropna()\n",
        "    scaler = StandardScaler()\n",
        "    X = df.drop(['return_lagging'], axis=1)\n",
        "    drop_cols = [col for i, col in enumerate(X.columns) if not keep_cols[i]]\n",
        "    X = X.drop(drop_cols, axis=1)\n",
        "    X = X.dropna()\n",
        "    X = scaler.fit_transform(X)\n",
        "    y = df['return_lagging'].values.reshape(-1,1)\n",
        "    y = scaler.fit_transform(y)\n",
        "    # 分割資料集為訓練集和測試集\n",
        "    X_train, y_train = X, y\n",
        "    # 創建隨機森林模型\n",
        "    rf = RandomForestRegressor(random_state=10, n_jobs=-1)\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_train)\n",
        "    # 計算測試集的 AUC 分數\n",
        "    mse_score = mean_squared_error(y_train, y_pred)\n",
        "    return mse_score"
      ],
      "metadata": {
        "id": "CnaCpd6ipAPy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_stock_data(sp500_stock_code, start_date, end_date):\n",
        "    data_combined = None\n",
        "    for stock_code in sp500_stock_code:\n",
        "        try:\n",
        "            data = get_stock_data(stock_code, start_date, end_date)\n",
        "            if data_combined is None:\n",
        "                data_combined = data\n",
        "            else:\n",
        "                data_combined = data_combined.append(data)\n",
        "            print(f'股票代碼 {stock_code} 資料抓取成功')\n",
        "        except Exception as e:\n",
        "            print(f\"股票代碼 {stock_code} 資料抓取失敗: {e}\")\n",
        "            continue\n",
        "    if data_combined is not None:\n",
        "        return data_combined\n",
        "    else:\n",
        "        print(\"沒有可用的股票資料\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "lDKZUnm6pFAb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sp500_ver1(data_combined, keep_cols):\n",
        "    data = copy.deepcopy(data_combined)\n",
        "    avg_mse_score_std = predict_stock_price_ver1(data, keep_cols)\n",
        "    return avg_mse_score_std\n",
        "def predict_sp500_ver2(data_combined, keep_cols):\n",
        "    data = copy.deepcopy(data_combined)\n",
        "    avg_mse_score_ret = predict_stock_price_ver2(data, keep_cols)\n",
        "    return avg_mse_score_ret"
      ],
      "metadata": {
        "id": "QWwpDmO3pGg2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKV28-LMpK38",
        "outputId": "9db1415f-a841-4f1f-a0e2-516a0dc7c0d9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deap\n",
            "  Downloading deap-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.22.4)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#寫基因演算法\n",
        "import deap\n",
        "from deap import algorithms, base, creator, tools\n",
        "import random\n",
        "import numpy as np\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "VG-EXhMDpJc1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#第一組資料\n",
        "start_date = datetime(2017, 1, 1)\n",
        "end_date = datetime(2019, 10, 30)\n",
        "keep_cols = np.random.randint(2, size=175)"
      ],
      "metadata": {
        "id": "hS-brTSapRHE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##雙目標函數"
      ],
      "metadata": {
        "id": "xhxX2t1QqXKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#設定基因和適應度函數\n",
        "creator.create('FitnessMin', base.Fitness, weights=(-1.0, -1.0))\n",
        "creator.create('Individual', list, fitness=creator.FitnessMin)\n",
        "\n",
        "#設定工具箱\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register('attr_bool', random.randint, 0, 1)\n",
        "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.attr_bool, n=175)\n",
        "toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
        "toolbox.register('mate', tools.cxTwoPoint)\n",
        "toolbox.register('mutate', tools.mutFlipBit, indpb=0.05)\n",
        "\n",
        "#設定適應度函數\n",
        "def evaluate_individual(individual):\n",
        "    keep_cols = individual\n",
        "    #計算mse平均值\n",
        "    avg_mse_score_std = predict_sp500_ver1(data_combined, keep_cols)\n",
        "    avg_mse_score_ret = predict_sp500_ver2(data_combined, keep_cols)\n",
        "\n",
        "    # 返回一個元組，包含兩個目標\n",
        "    return (avg_mse_score_std, avg_mse_score_ret)\n",
        "\n",
        "toolbox.register('evaluate', evaluate_individual)\n",
        "toolbox.register('select', tools.selNSGA2)\n",
        "#設定演化參數\n",
        "population_size = 20\n",
        "number_of_generations = 50\n",
        "probability_of_crossover = 0.5\n",
        "probability_of_mutation = 0.5\n",
        "\n",
        "#初始化族群\n",
        "population = toolbox.population(n=population_size)\n",
        "\n",
        "#執行演化\n",
        "for generation in range(number_of_generations):\n",
        "    print(f\"第{generation}次迭代成功\")\n",
        "    #交配變異\n",
        "    offspring = algorithms.varAnd(population, toolbox, cxpb=probability_of_crossover, mutpb=probability_of_mutation)\n",
        "    #計算每個個體的適應度\n",
        "    fitnesses = map(toolbox.evaluate, offspring)\n",
        "    #跟新適應度\n",
        "    for ind, fit in zip(offspring, fitnesses):\n",
        "        ind.fitness.values = fit\n",
        "    #跟新種群\n",
        "    population = toolbox.select(offspring, k=population_size)\n",
        "    \n",
        "#獲得最佳解\n",
        "best_individual = tools.selBest(population, k=1)[0]\n",
        "best_fitness = best_individual.fitness.values\n",
        "\n",
        "print('Best individual:', best_individual)\n",
        "print('Best fitness:', best_fitness)\n",
        "\n"
      ],
      "metadata": {
        "id": "HAPtfYxhqZ-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A0aOoMJVqczK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#最佳化之後的特徵選擇"
      ],
      "metadata": {
        "id": "IqayVK6LqgOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##用最佳化特徵去預測每檔股票波動率和報酬率"
      ],
      "metadata": {
        "id": "TY7xJ0WqqlqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_std(data, keep_cols):\n",
        "    # 根据 keep_cols 的值删除需要删除的列\n",
        "    # 用除了漲跌的欄位作為自變數，去預測股價漲跌\n",
        "    df = copy.deepcopy(data)\n",
        "    df.fillna(0, inplace=True)\n",
        "    df['stddev_lagging'] = df['stddev'].shift(-1)\n",
        "    df = df.dropna()\n",
        "    scaler = StandardScaler()\n",
        "    X = df.drop(['stddev_lagging'], axis=1)\n",
        "    drop_cols = [col for i, col in enumerate(X.columns) if not keep_cols[i]]\n",
        "    X = X.drop(drop_cols, axis=1)\n",
        "    X = X.dropna()\n",
        "    X = scaler.fit_transform(X)\n",
        "    y = df['stddev_lagging'].values.reshape(-1,1)\n",
        "    y = scaler.fit_transform(y)\n",
        "    # 分割資料集為訓練集和測試集\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
        "    # 創建隨機森林模型\n",
        "    rf = RandomForestRegressor(random_state=10, n_jobs=-1)\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    # 計算平均標準差（stddev）分數\n",
        "    avg_stddev = np.mean(y_pred)\n",
        "    return avg_stddev"
      ],
      "metadata": {
        "id": "8n1M1l0yqmoQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_ret(data, keep_cols):\n",
        "    # 根据 keep_cols 的值删除需要删除的列\n",
        "    # 用除了漲跌的欄位作為自變數，去預測股價漲跌\n",
        "    df = copy.deepcopy(data)\n",
        "    df.fillna(0, inplace=True)\n",
        "    df['return_lagging'] = df['return'].shift(-1)\n",
        "    df = df.dropna()\n",
        "    scaler = StandardScaler()\n",
        "    X = df.drop(['return_lagging'], axis=1)\n",
        "    drop_cols = [col for i, col in enumerate(X.columns) if not keep_cols[i]]\n",
        "    X = X.drop(drop_cols, axis=1)\n",
        "    X = X.dropna()\n",
        "    X = scaler.fit_transform(X)\n",
        "    y = df['return_lagging'].values.reshape(-1,1)\n",
        "    y = scaler.fit_transform(y)\n",
        "    # 分割資料集為訓練集和測試集\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
        "    # 創建隨機森林模型\n",
        "    rf = RandomForestRegressor(random_state=10, n_jobs=-1)\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    avg_return = np.mean(y_pred)\n",
        "    return avg_return"
      ],
      "metadata": {
        "id": "RCc-asdBqq5x"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sp500(sp500_top_250, best_individual):\n",
        "    data_dict = {}\n",
        "    for stock_code in sp500_top_250:\n",
        "        try:\n",
        "            #取得股票資料\n",
        "            start_date = datetime.datetime(2018, 10, 31)\n",
        "            end_date = datetime.datetime(2020, 12, 31)\n",
        "            data = get_stock_data(stock_code, start_date, end_date)\n",
        "            # 根據最佳化結果進行特徵選擇\n",
        "            keep_cols = best_individual\n",
        "            #進行預測\n",
        "            avg_std_score = predict_std(data, keep_cols)\n",
        "            avg_ret_score = predict_ret(data, keep_cols)\n",
        "            \n",
        "            print(f\"股票代碼 {stock_code} 預測成功\")\n",
        "        except Exception as e:\n",
        "            print(f\"股票代碼 {stock_code} 預測失敗: {e}\")\n",
        "            continue\n",
        "\n",
        "        #預測結果添加到字典中\n",
        "        data_dict[stock_code] = {'隱含波動度':avg_std_score, '隱含報酬率':avg_ret_score}\n",
        "    df = pd.DataFrame.from_dict(data_dict, orient=\"index\")\n",
        "    \n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "cfhRXEnsqt3i"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#建構投資組合\n",
        "#先依照波動度將投組分為低波動(前30%)、中型波動、高波動(後30%)\n",
        "#再依照波動度將投組分為低報酬(前30%)、中型報酬、高報酬(後30%)\n",
        "#輸入df，輸出低波動、高報酬的股票代碼LIST"
      ],
      "metadata": {
        "id": "XnYdsnxruFKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_stocks(df):\n",
        "    volatility_quantiles = df['隱含波動度'].quantile([0.3, 0.7])\n",
        "    df['波動度分類'] = pd.cut(df['隱含波動度'], bins=[-np.inf, volatility_quantiles.iloc[0],\n",
        "                                            volatility_quantiles.iloc[1],\n",
        "                                            np.inf],labels=['低波動', '中等波動', '高波動'])\n",
        "    returns_quantiles = df['隱含報酬率'].quantile([0.3, 0.7])\n",
        "    df['報酬率分類'] = pd.cut(df['隱含報酬率'], bins=[-np.inf, returns_quantiles.iloc[0], returns_quantiles.iloc[1], np.inf], labels=['低報酬', '中等報酬', '高報酬'])\n",
        "\n",
        "    # 選取低波動且高報酬的股票代碼\n",
        "    filtered_stocks = df[(df['波動度分類'] == '低波動') & (df['報酬率分類'] == '高報酬')].index.tolist()\n",
        "\n",
        "    return filtered_stocks, df"
      ],
      "metadata": {
        "id": "kSBCIbDouLjO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stock_data_only(stock_code, start_date, end_date):\n",
        "    #取得股票資料\n",
        "    df = pdr.get_data_yahoo([stock_code], start_date, end_date)\n",
        "    df.columns = [col.lower() for col in df.columns]\n",
        "    df['return'] = df['adj close'].pct_change()\n",
        "    df = df.dropna()\n",
        "    return df"
      ],
      "metadata": {
        "id": "ZZJanodyuRiQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "VJTYd1zAuT_m"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_portfolio_returns(filtered_stocks, start_date, end_date):\n",
        "    portfolio_returns = []\n",
        "    portfolio_returns_sp_500=[]\n",
        "    stock_code_sp_500 = 'SPY'\n",
        "    dates = pd.date_range(start=start_date, end=end_date, freq='B')\n",
        "    for date in dates:\n",
        "        # 取得當天的股票資料\n",
        "        stock = []\n",
        "        for stock_code in filtered_stocks:\n",
        "            stock_data = get_stock_data_only(stock_code, date - timedelta(days=1), date + timedelta(days=1))\n",
        "            if not stock_data.empty:\n",
        "                stock.append(stock_data.iloc[0]['return'])\n",
        "            else:\n",
        "                stock.append(0)     \n",
        "        avg_return = sum(stock) / len(stock)\n",
        "        portfolio_returns.append(avg_return)\n",
        "\n",
        "        stock_data_sp_500 = get_stock_data_only(stock_code_sp_500, date - timedelta(days=1), date + timedelta(days=1))\n",
        "        if not stock_data_sp_500.empty:\n",
        "            return_sp_500 = stock_data_sp_500.iloc[0]['return']\n",
        "        else:\n",
        "            return_sp_500 = 0\n",
        "        portfolio_returns_sp_500.append(return_sp_500)\n",
        "   \n",
        "    df = pd.DataFrame({'profit':np.cumsum(portfolio_returns), 'sp 500 return':np.cumsum(portfolio_returns_sp_500)}, index=dates)\n",
        "    df.plot(grid=True, figsize=(16, 6))\n",
        "    plt.legend()\n",
        "    plt.ylabel('Profit')\n",
        "    plt.xlabel('date')\n",
        "    plt.title('Portfolio Returns')\n",
        "    plt.show()\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    # 計算總利潤、股權、回撤百分比和回撤\n",
        "    df['equity'] = df['profit']+1\n",
        "    df['drawdown_percent'] = (df['equity'] / df['equity'].cummax())-1\n",
        "    df['drawdown'] = df['equity'] - df['equity'].cummax()\n",
        "    fig, ax = plt.subplots(figsize = (16,6))\n",
        "    high_index = df[df['profit'].cummax() == df['profit']].index\n",
        "    df['profit'].plot(label = 'Total Profit', ax = ax, c = 'r', grid=True)\n",
        "    plt.fill_between(df['drawdown'].index, df['drawdown'], 0, facecolor = 'r', label = 'Drawdown', alpha = 0.5)\n",
        "    plt.scatter(high_index, df['profit'].loc[high_index], c = '#02ff0f', label = 'High')\n",
        "    plt.legend()\n",
        "    plt.ylabel('Accumulated Profit Return')\n",
        "    plt.xlabel('Time')\n",
        "    plt.title('Portfolio Profit & Drawdown',fontsize  = 16)\n",
        "    plt.show()\n",
        "    profit = df['profit'].iloc[-1]\n",
        "    mdd = abs(df['drawdown_percent'].min())\n",
        "    calmarratio = profit/mdd\n",
        "    print(\"portfolio return & risk \")\n",
        "    print(f'return: ${np.round(profit, 4)*100}%')\n",
        "    print(f'mdd: {np.round(mdd, 4)*100}%')\n",
        "    print(f'calmar ratio: {np.round(calmarratio, 2)}')\n",
        "\n",
        "    #計算持有大盤\n",
        "    df_sp500 = pd.DataFrame({'profit':np.cumsum(portfolio_returns_sp_500)})\n",
        "    df_sp500['equity'] = df_sp500['profit']+1\n",
        "    df_sp500['drawdown_percent'] = (df_sp500['equity'] / df_sp500['equity'].cummax())-1\n",
        "    df_sp500['drawdown'] = df_sp500['equity'] - df_sp500['equity'].cummax()\n",
        "    fig, ax = plt.subplots(figsize = (16,6))\n",
        "    high_index = df_sp500[df_sp500['profit'].cummax() == df_sp500['profit']].index\n",
        "    df_sp500['profit'].plot(label = 'Total Profit', ax = ax, c = 'r', grid=True)\n",
        "    plt.fill_between(df_sp500['drawdown'].index, df_sp500['drawdown'], 0, facecolor = 'r', label = 'Drawdown', alpha = 0.5)\n",
        "    plt.scatter(high_index, df_sp500['profit'].loc[high_index], c = '#02ff0f', label = 'High')\n",
        "    plt.legend()\n",
        "    plt.ylabel('Accumulated Profit Return')\n",
        "    plt.xlabel('Time')\n",
        "    plt.title('SP500 Profit & Drawdown',fontsize  = 16) \n",
        "    plt.ylim(top=df['profit'].max())\n",
        "    plt.show()\n",
        "    profit = df_sp500['profit'].iloc[-1]\n",
        "    mdd = abs(df_sp500['drawdown_percent'].min())\n",
        "    calmarratio = profit/mdd\n",
        "    print(\"sp 500 return & risk \")\n",
        "    print(f'return: ${np.round(profit, 4)*100}%')\n",
        "    print(f'mdd: {np.round(mdd, 4)*100}%')\n",
        "    print(f'calmar ratio: {np.round(calmarratio, 2)}')\n",
        "    \n",
        "    return portfolio_returns, portfolio_returns_sp_500"
      ],
      "metadata": {
        "id": "E01GDObDuWrQ"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}